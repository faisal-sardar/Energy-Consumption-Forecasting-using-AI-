installing libraries
# installing jdatetime for converting date to Gregotian
# !pip install scikit-learn
# !pip install matplotlib
%pip install jdatetime
%pip install scikit-optimize
%pip install bayesian-optimization
Collecting jdatetime
  Downloading jdatetime-4.1.1-py3-none-any.whl (13 kB)
Installing collected packages: jdatetime
Successfully installed jdatetime-4.1.1
Collecting scikit-optimize
  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100.3/100.3 kB 2.2 MB/s eta 0:00:00
Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.3.2)
Collecting pyaml>=16.9 (from scikit-optimize)
  Downloading pyaml-23.9.7-py3-none-any.whl (23 kB)
Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.23.5)
Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.11.3)
Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.2.2)
Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)
Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.2.0)
Installing collected packages: pyaml, scikit-optimize
Successfully installed pyaml-23.9.7 scikit-optimize-0.9.0
Collecting bayesian-optimization
  Downloading bayesian_optimization-1.4.3-py3-none-any.whl (18 kB)
Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.23.5)
Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.11.3)
Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.2.2)
Collecting colorama>=0.4.6 (from bayesian-optimization)
  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)
Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.3.2)
Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.2.0)
Installing collected packages: colorama, bayesian-optimization
Successfully installed bayesian-optimization-1.4.3 colorama-0.4.6

Importing Data
import pandas as pd # to import the excel file
import numpy as np
from data_manipulation import hourly_rows_data

## importing data files
data_df = pd.read_excel("consumption.xlsx") # includes each day in a row with hours of the day as columns
temperatue_df = pd.read_csv("temperature.csv") # includes the hourly temprature of eaach day

# convert our original dataframe to have each row represent an hour
hourly_data_frame = hourly_rows_data(df = data_df)

# adding another column to the new_df, which is the temperature of each hour using the temp_df
# changing the format to pd.datetime
temperatue_df["time"] = pd.to_datetime(temperatue_df['time'], format='%Y-%m-%dT%H:%M')

# now we concatinate the two data frames based on the 'time' column
concatinated_df = pd.concat([hourly_data_frame.set_index('time'), temperatue_df.set_index('time')], axis=1, join='inner')

# Reset the index to make 'time' a column again
concatinated_df.reset_index(inplace=True)
concatinated_df.head(2)
changed the data frame's shape from (730, 25) to (17520, 2)

time	power	temp
0	2021-03-21 01:00:00	683.189471	6.7
1	2021-03-21 02:00:00	627.645948	6.1
Plotting to get some information
plotting the "power" with respect to temperatue and time to see the relation between them

# plotting temperatue vs power consumption
import matplotlib.pyplot as plt
import numpy as np

unique_temps = np.unique(concatinated_df['temp'])

plt.figure(figsize=(20, 4))
# Plotting
plt.subplot(1, 2, 1)
plt.bar(unique_temps, concatinated_df.groupby('temp')['power'].mean())
plt.xlabel('Temperature')
plt.ylabel('Mean power')
plt.title('Mean power consumption vs Temperature')

plt.subplot(1, 2, 2)
# Plotting the power over the time column
plt.plot(concatinated_df['time'][:100], concatinated_df['power'][:100], label='power', marker='o', linestyle='-', color='b')
plt.title('Plotting power over time')
plt.xlabel('Time')
plt.ylabel('power')
plt.legend()
plt.grid(True)

# Adjust layout to prevent clipping of titles
plt.tight_layout()
plt.show()


from data_manipulation import std_normalizer ,create_historical_dataset

# Normalizing using the Standard Deviation Normalization method
normalized_concatinated_df , (normalized_mean , normalized_std) = std_normalizer(df= concatinated_df,col_name= "power")

# make a historical dataset for models to predict on.
window_size = 3
exclude_columns = ['time']  # Specify columns to exclude from lag feature creation
historical_dataframe = create_historical_dataset(normalized_concatinated_df, window_size, exclude_columns)

Normalization is done for column : power
# Drop any other columns that are not features or the target variable
features = historical_dataframe.drop(columns=['target_power','time'],axis =1).astype('float32')
target = historical_dataframe['target_power'].astype('float32')

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)
gb.plot_importance(final_model)
<Axes: title={'center': 'Feature importance'}, xlabel='Feature importance', ylabel='Features'>
lgb.plot_tree(final_model, tree_index = 0, show_info=['split_gain'], precision=2, orientation='vertical')
# Save the plot as a PNG file with higher DPI
# plt.savefig('tree_plot.png', dpi=1200)
